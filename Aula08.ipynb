{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC52WYa49N5c91b50uv0Z5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraSilvaa/FATEC_PLN_Codes/blob/master/Aula08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aula 8 - Introdução a ML para PLN\n",
        "\n",
        "##Na aula de hoje vamos trabalhar com dois modelos clássicos: **Naives** (ou Ingênuo) e o modelo de suporte a vetor **(Support Vector Machine -SVM)**\n",
        "\n",
        "\n",
        "###**Modelo de Naives:** é baseado no teorema de Bayes que consiste na probabilidade composta (um evento ocorrer apos outro evento)\n",
        "####Precisa ter uma base de referencia para indicar quais são as probabilidades de um evento acontecer\n",
        "\n",
        "* **P(C) =** Evento qualquer que pode acontecer (probabilidade simples)\n",
        "\n",
        "* **P(C|X) =** Probabilidade de um evento acontecer depois de um evento(probabilidade composta)\n",
        "\n",
        "\n",
        "\n",
        "###Sendo assim as probabilidades podem ser **dependentes**: onde o calculo é mais complexo ou **independentes**: onde o calculo é mais simples\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XmCWvtyEB2EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 01 - Aplicação do modelo de Naives em um texto"
      ],
      "metadata": {
        "id": "B8-VIlgsJ12K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PASSO 1 - Modelo a ser treinado\n",
        "corpus = [\n",
        "    (\"Eu amo PLN\",\"positivo\"),\n",
        "    (\"Eu odeio bugs\",\"negativo\"),\n",
        "    (\"Amo resolver problemas\", \"positivo\"),\n",
        "    (\"Odeio erros\", \"negativo\"),\n",
        "    (\"Bugs legais\", \"positivo\"),\n",
        "    (\"Resolver\", \"positivo\"),\n",
        "    (\"Eu não\",\"negativo\")\n",
        "]\n",
        "\n",
        "#PASSO 2 - Agora iremos pré-processar o texto\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def preprocess_text(text):\n",
        "  return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "processed_corpus = [(preprocess_text(text), label) for text, label in corpus]\n",
        "print(processed_corpus)\n",
        "\n",
        "#PASSO 03 Calculando as Probabilidades das frases\n",
        "class_counts = Counter()  # Sara explicação: Cria um contador para contar a frequência de cada classe.\n",
        "word_counts = defaultdict(Counter)  # Sara explicação: Cria um dicionário de contadores, um para cada classe.\n",
        "total_words = defaultdict(int)  # Sara explicação: Cria um dicionário para contar o total de palavras por classe.\n",
        "\n",
        "for words, label in processed_corpus:  # Sara explicação: Percorre o corpus processado, que contém palavras e seus rótulos.\n",
        "  class_counts[label] += 1  # Sara explicação: Conta a frequência de cada classe no corpus.\n",
        "  for word in words:  # Sara explicação: Itera sobre as palavras de cada exemplo no corpus.\n",
        "    word_counts[label][word] += 1  # Sara explicação: Conta a frequência de cada palavra dentro de uma classe.\n",
        "    total_words[label]  # Sara explicação: Soma o total de palavras por classe.\n",
        "\n",
        "total_examples = sum(class_counts.values())  # Sara explicação: Calcula o total de exemplos no corpus.\n",
        "prior_probabilities = {cls: count / total_examples for cls, count in class_counts.items()}  # Sara explicação: Calcula a probabilidade a priori para cada classe.\n",
        "\n",
        "def conditional_probability(word, label, alpha=1):  # Sara explicação: Função para calcular a probabilidade condicional de uma palavra em uma classe.\n",
        "  return (word_counts[label][word] + alpha) / (total_words[label] + alpha * len(word_counts[label]))  # Sara explicação: Aplica o método de suavização de Laplace para calcular a probabilidade condicional.\n",
        "\n",
        "#PASSO 04 - Classificar um novo texto\n",
        "def predict(text):  # Sara explicação: Função para prever a classe de um novo texto.\n",
        "  words = preprocess_text(text)  # Sara explicação: Processa o texto (como tokenizar, remover stop words, etc.).\n",
        "  probabilities = {}  # Sara explicação: Dicionário para armazenar as probabilidades de cada classe.\n",
        "\n",
        "  for label in class_counts.keys():  # Sara explicação: Intera sobre todas as classes possíveis.\n",
        "    probabilities[label] = prior_probabilities[label]  # Sara explicação: Começa com a probabilidade a priori da classe.\n",
        "    for word in words:  # Sara explicação: Para cada palavra no texto, atualiza a probabilidade da classe.\n",
        "      probabilities[label] *= conditional_probability(word, label)  # Sara explicação: Multiplica a probabilidade condicional de cada palavra na classe.\n",
        "      return max(probabilities, key=probabilities.get), probabilities  # Sara explicação: Retorna a classe com a maior probabilidade.\n",
        "\n",
        "#PASSO 5 - Teste com um novo texto\n",
        "novo_texto = \"Eu amo resolver bugs\"  # Sara explicação: Define um novo texto para prever a classe.\n",
        "classe,probs = predict(novo_texto)  # Sara explicação: Diz a classe do novo texto e calcula as probabilidades.\n",
        "\n",
        "print(f'O texto \"{novo_texto}\"')  # Sara explicação: Imprime o texto original.\n",
        "print(f'é classificado como: \"{classe}\"')  # Sara explicação: Exibe a classe prevista.\n",
        "print(f'Probabilidades:')  # Sara explicação: Inicia a impressão das probabilidades de cada classe.\n",
        "for label, prob in probs.items():  # Sara explicação: Itera sobre as probabilidades de todas as classes.\n",
        "  print(f\"{label}: {prob}\")  # Sara explicação: Exibe a probabilidade de cada classe.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYSf64ngG8f3",
        "outputId": "d53c42b9-5aab-4c75-9b2f-2f990553c2aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['eu', 'amo', 'pln'], 'positivo'), (['eu', 'odeio', 'bugs'], 'negativo'), (['amo', 'resolver', 'problemas'], 'positivo'), (['odeio', 'erros'], 'negativo'), (['bugs', 'legais'], 'positivo'), (['resolver'], 'positivo'), (['eu', 'não'], 'negativo')]\n",
            "O texto \"Eu amo resolver bugs\"\n",
            "é classificado como: \"positivo\"\n",
            "Probabilidades:\n",
            "positivo: 0.16326530612244897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 2 - Modelo de SVM (Support Vector Machine)\n",
        "##É um modelo de aprendizagem supervisionado que faz classificação e regressão\n",
        ""
      ],
      "metadata": {
        "id": "ULTmUPDOXcx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1 -  Importação das bibliotecas a serem utilizadas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Sara explicação: Importa a classe para converter texto em uma matriz TF-IDF.\n",
        "from sklearn.svm import SVC  # Sara explicação: Importa o modelo de Classificador SVM (Máquinas de Vetores de Suporte).\n",
        "from sklearn.model_selection import train_test_split  # Sara explicação: Importa a função para dividir os dados em treino e teste.\n",
        "from sklearn.metrics import classification_report  # Sara explicação: Importa a função para avaliar o desempenho do modelo.\n",
        "\n",
        "#Passo 2 - # Sara explicação: Definindo um conjunto de frases (corpus) de exemplo\n",
        "corpus = [\n",
        "    \"Eu amo PLN\", \"Eu odeio bugs\", \"Eu amo resolver problemas\",\n",
        "  \"Odeio erros\", \"Amo programação\", \"Não gosto de falhas\"\n",
        "]\n",
        "\n",
        "classes = [ \"negativo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\"]\n",
        "\n",
        "\n",
        "# Passo 3 -  Pre processamento e vetorização\n",
        "vectorizer = TfidfVectorizer()  # Sara explicação: Cria o vetor de transformação TF-IDF para converter texto em uma matriz de características.\n",
        "X = vectorizer.fit_transform(corpus)  # Sara explicação: Aplica o TF-IDF no corpus e cria a matriz de características (X).\n",
        "y = classes  # Sara explicação: Define as classes (rótulos) para os dados (y).\n",
        "\n",
        "#Passo 4 -  Dividir os dados e Treinar o modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  # Sara explicação: Divide os dados em 70% para treino e 30% para teste, mantendo a aleatoriedade.\n",
        "svm_model = SVC(kernel='linear')  # Sara explicação: Cria o modelo SVM com kernel linear (para classificação linear).\n",
        "svm_model.fit(X_train, y_train)  # Sara explicação: Treina o modelo SVM usando os dados de treino.\n",
        "\n",
        "# Passo 5 - Avaliar o modelo\n",
        "y_pred = svm_model.predict(X_test)  # Sara explicação: Usando o modelo treinado para fazer previsões nos dados de teste.\n",
        "print(classification_report(y_test, y_pred))  # Sara explicação: Imprime o relatório de classificação com métricas de desempenho"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDmg34BXXcWo",
        "outputId": "bc737e37-9ea5-4e50-8739-5e63ec02188e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      0.50      0.67         2\n",
            "    positivo       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.50      0.25      0.33         2\n",
            "weighted avg       1.00      0.50      0.67         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explicação das classificações\n",
        "###**Precision (Precisão):** Mede a exatidão das previsões positivas.\n",
        "\n",
        "###**\"negativo\":** 1.00 (100% de precisão para negativos).\n",
        "###**\"positivo\":** 0.00 (nenhuma previsão correta para positivos).\n",
        "###**Recall (Revocação ou Sensibilidade):** Mede a capacidade de identificar todas as instâncias positivas.\n",
        "\n",
        "###**\"negativo\": 0.50** (50% de acerto para negativos).\n",
        "###**\"positivo\": 0.00** (não encontrou nenhum positivo).\n",
        "###**F1-Score (F1-Score):** Média harmônica entre precisão e recall.\n",
        "\n",
        "###**\"negativo\":** 0.67 (bom desempenho para negativos).\n",
        "###**\"positivo\":** 0.00 (não conseguiu prever positivos).\n",
        "###**Support (Suporte):** Número de exemplos reais de cada classe no conjunto de teste.\n",
        "\n",
        "###**\"negativo\":** 2 exemplos.\n",
        "###\"**positivo\":** 0 exemplos (o que comprometeu o desempenho para \"positivo\").\n",
        "###**Accuracy (Acurácia):** 50% de previsões corretas no total.\n",
        "\n",
        "###**Macro avg (Média Macro) e Weighted avg (Média Ponderada):** A média das métricas entre as classes, ponderando ou não pelo número de exemplos"
      ],
      "metadata": {
        "id": "ZDuC_eMQgkXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 03 - A comparação entre os 2 modelos"
      ],
      "metadata": {
        "id": "uw9c9oeBbec_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importar Bibliotecas como no exemplo anterior\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Baixar o dataset de exemplo\n",
        "nltk.download('movie_reviews')  # Sara explicação: Baixa o conjunto de dados de resenhas de filmes do NLTK.\n",
        "from nltk.corpus import movie_reviews  # Sara explicação: Importa o corpus de resenhas de filmes.\n",
        "\n",
        "# 2. Preparação dos dados\n",
        "  # Coleta de textos e classes\n",
        "documents = [(\" \".join(movie_reviews.words(fileid)), category)  # Sara explicação: Coleta as palavras de cada arquivo de resenha e as associa à categoria.\n",
        "              for category in movie_reviews.categories()  # Sara explicação: Para cada categoria (pos/neg), extrai os arquivos de resenhas.\n",
        "              for fileid in movie_reviews.fileids(category)]  # Sara explicação: Para cada arquivo de resenha em cada categoria.\n",
        "\n",
        "  # Separar textos e rótulos\n",
        "texts, labels = zip(*documents)  # Sara explicação: Separa os textos e rótulos (classes) em duas listas (texts e labels).\n",
        "\n",
        "  # Transformar rótulos (positivo/negativo) em 0 e 1\n",
        "from sklearn.preprocessing import LabelEncoder  # Sara explicação: Importa a classe que converte rótulos categóricos em valores numéricos.\n",
        "label_encoder = LabelEncoder()  # Sara explicação: Cria o objeto que fará a conversão dos rótulos.\n",
        "labels = label_encoder.fit_transform(labels)  # Sara explicação: Converte os rótulos (positivo/negativo) em 0 e 1.\n",
        "\n",
        "  # Dividir dados em treino e teste\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.3, random_state=42)  # Sara explicação: Divide os dados em 70% para treino e 30% para teste.\n",
        "\n",
        "# 3. Representação do texto com TF-IDF\n",
        "  # Criar o vetorizador TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Sara explicação: Cria o vetorizador TF-IDF, limitando a 5000 palavras mais relevantes.\n",
        "\n",
        "  # Ajustar e transformar os textos\n",
        "X_train = vectorizer.fit_transform(texts_train)  # Sara explicação: Aplica o TF-IDF nos textos de treino.\n",
        "X_test = vectorizer.transform(texts_test)  # Sara explicação: Aplica o TF-IDF nos textos de teste (sem ajustar).\n",
        "\n",
        "# 4. Treinar os modelos\n",
        "  # Treinamento do Naive Bayes\n",
        "nb_model = MultinomialNB()  # Sara explicação: Cria o modelo de Naive Bayes para classificação de múltiplas classes.\n",
        "nb_model.fit(X_train, labels_train)  # Sara explicação: Treina o modelo Naive Bayes com os dados de treino.\n",
        "  # Predição\n",
        "nb_predictions = nb_model.predict(X_test)  # Sara explicação: Faz previsões nos dados de teste usando o modelo Naive Bayes.\n",
        "\n",
        "  # Treinamento do SVM\n",
        "svm_model = SVC(kernel='linear')  # Sara explicação: Cria o modelo SVM com kernel linear (para classificação linear).\n",
        "svm_model.fit(X_train, labels_train)  # Sara explicação: Treina o modelo SVM com os dados de treino.\n",
        "  # Predição\n",
        "svm_predictions = svm_model.predict(X_test)  # Sara explicação: Faz previsões nos dados de teste usando o modelo SVM.\n",
        "\n",
        "# 5. Avaliação\n",
        "  # Avaliação do Naive Bayes\n",
        "print(\"****Naive Bayes Performance:*****\")  # Sara explicação: Exibe o título para o desempenho do modelo Naive Bayes.\n",
        "  # Limitar a 5.000 palavras mais comuns\n",
        "print(classification_report(labels_test, nb_predictions, target_names=label_encoder.classes_))  # Sara explicação: Exibe o relatório de classificação do Naive Bayes, mostrando métricas como precisão, recall e F1-score.\n",
        "\n",
        "  # Avaliação do SVM\n",
        "print(\"*****SVM Performance:*****\")  # Sara explicação: Exibe o título para o desempenho do modelo SVM.\n",
        "print(classification_report(labels_test, svm_predictions, target_names=label_encoder.classes_))  # Sara explicação: Exibe o relatório de classificação do SVM."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3DfdU7Sc7Z3",
        "outputId": "7433ad04-3d82-4ad7-ba67-3518b2fe3bec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Naive Bayes Performance:*****\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.79      0.84      0.81       302\n",
            "         pos       0.82      0.77      0.80       298\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n",
            "*****SVM Performance:*****\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.80      0.81       302\n",
            "         pos       0.81      0.82      0.81       298\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    }
  ]
}